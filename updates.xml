<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>PatientExperience-QDC website</title>
<link>https://CDU-data-science-team.github.io/PatientExperience-QDC/updates.html</link>
<atom:link href="https://CDU-data-science-team.github.io/PatientExperience-QDC/updates.xml" rel="self" type="application/rss+xml"/>
<description>Website for the NHS England funded Patient Experience Qualitative Data Categorisation project</description>
<generator>quarto-1.3.361</generator>
<lastBuildDate>Wed, 31 May 2023 00:00:00 GMT</lastBuildDate>
<item>
  <title>pxtextmining API: enabling access to project outputs</title>
  <dc:creator>YiWen Hon</dc:creator>
  <link>https://CDU-data-science-team.github.io/PatientExperience-QDC/posts/update-23-05-31/index.html</link>
  <description><![CDATA[ 



<p>Our latest major project milestone is the release of a model API. This blog post will explain what this is, how we have achieved it, and what our next steps are.</p>
<section id="what-is-an-api" class="level2">
<h2 class="anchored" data-anchor-id="what-is-an-api">What is an API?</h2>
<p>API stands for “application programming interface”. Most of the digital services and platforms that we use have an API. It is essentially a gateway that allows access to information. For example, when you ask an Alexa or Siri what the weather is, it will communicate with a weather service API to obtain the information for you. When you get an email notification on your phone, this is because your email service provider is sending a notice via its API, to your phone.</p>
<p>Still confused? <a href="https://youtu.be/s7wmiS2mSXY">This video</a> may help.</p>
<p>The pxtextmining API allows people to utilise the machine learning models that we have trained for the project to label new text. It makes the model accessible over the internet, without any installation or downloads required. All that’s needed is a few lines of code. Examples are available on the <a href="https://cdu-data-science-team.github.io/pxtextmining/reference/API/API/">pxtextmining documentation website</a>.</p>
</section>
<section id="why-did-we-do-it" class="level2">
<h2 class="anchored" data-anchor-id="why-did-we-do-it">Why did we do it?</h2>
<p>The API was created to separate our R/Shiny-based experiencesdashboard frontend and the Python-based pxtextmining backend. This independence means more flexibility in the development of each. This also means that some participating trusts can utilise the model only, if they wish, and integrate it into their existing visualisation tools / dashboards for exploring patient feedback data.</p>
<p>We also recognise that although the code and models for pxtextmining are available openly on github, many organisations may not have the technical resources, time, or capability to run it themselves. Making the model available via an API reduces the barrier to entry and ensures that the project outputs are more accessible.</p>
</section>
<section id="how-did-we-do-it" class="level2">
<h2 class="anchored" data-anchor-id="how-did-we-do-it">How did we do it?</h2>
<p>The API is built using the open source <a href="https://fastapi.tiangolo.com/lo/">Python FastAPI package</a>. Users of the API must format their data in JSON format, and submit this to the API endpoint via a POST request. This then gets cleaned and passed through the machine learning model, and the outputted labels are returned, also in JSON format. We utilised the <a href="https://www.uvicorn.org/">Uvicorn</a> library to test the API locally, and have ensured that the API is covered by unit tests. We are hosting the API on the Strategy Unit’s Rstudio Connect server. Deploying it was very simple, luckily! The diagram below shows how the API works.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://CDU-data-science-team.github.io/PatientExperience-QDC/posts/update-23-05-31/px_diagram.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Diagram of API</figcaption>
</figure>
</div>
</section>
<section id="whats-next" class="level2">
<h2 class="anchored" data-anchor-id="whats-next">What’s next?</h2>
<p>The API currently uses a support vector classifier model which is quite small and fast. Even so, we have to balance the load on the server with waiting times, limiting the number of requests to 1000 at a time to prevent timeouts. We also have a transformer-based model which is very large and slow, taking several minutes to make predictions from text, which we have not implemented an API for. Our next step is to figure out how to do this without completely taking over the server’s resources, and impacting too much on the user experience.</p>
<p>We also want to make sure that participating trusts are able to make use of the API, and help demystify it. Communication is key, and blog posts like this will hopefully help. We are also providing example scripts showing how to create API queries in R and Python, and have built a <a href="https://connect.strategyunitwm.nhs.uk/content/0049176a-56d7-40c9-bf07-26262e9ee53c">simple website</a> that shows the API and the model in action.</p>
<p>The model that is used in the API is also still a work in progress, we know we have a lot of work to do to improve performance. But now that the technical infrastructure is in place, it should be relatively easy to update with new models, when we train them. If you’re interested in using the API, do get in touch!</p>


</section>

 ]]></description>
  <category>news</category>
  <guid>https://CDU-data-science-team.github.io/PatientExperience-QDC/posts/update-23-05-31/index.html</guid>
  <pubDate>Wed, 31 May 2023 00:00:00 GMT</pubDate>
  <media:content url="https://CDU-data-science-team.github.io/PatientExperience-QDC/posts/update-23-05-31/px_diagram.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Machine learning update</title>
  <dc:creator>YiWen Hon</dc:creator>
  <link>https://CDU-data-science-team.github.io/PatientExperience-QDC/posts/update-23-03-13/index.html</link>
  <description><![CDATA[ 



<p>We’ve had a chance to play around with a few different model architectures now and the main finding is that so far, as in Phase 1 and other <a href="https://www.sciencedirect.com/science/article/pii/S1386505621002689?via%3Dihub">similar projects</a>, Support Vector Classifier is performing the best. We are currently prototyping using only some of the final dataset, and focusing on predicting 1 of 13 overarching ‘major categories’. These are divided into a further 50+ subcategories, which our models are not yet trained to detect, but this will be the next step, once the framework is finalised.</p>
<p>We have also tried out Distilbert uncased, which is performing well, if not slightly better, than SVC. However, it’s taking a long time to train (around 6 hours on average) and is very large, around 1 GB in size. It also takes a long time to make predictions, around 1 minute per 1000 comments. When we have the final dataset we’ll have a clearer picture of which model will be best suited for the needs of the project.</p>
<p>The latest development is that we’re able to combine the text with the ‘question type’ feature. Most of the questions asked by trusts can be divided into one of three main types:</p>
<ul>
<li><p>What did we do well?</p></li>
<li><p>What could we do better?</p></li>
<li><p>Any other comments / no specific question</p></li>
</ul>
<p>Including the question type with the text of the comment has improved performance slightly. The way this has been done with BERT can be seen in the diagram below. We tried both of the methods found in <a href="https://stackoverflow.com/a/73576407/17852099">this stackoverflow post</a>, which produced similar results. We went for the concatenated layers, however, as this means the model architecture is more flexible and can be adapted to include other features as well, if necessary.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://CDU-data-science-team.github.io/PatientExperience-QDC/posts/update-23-03-13/model_architecture.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Distilbert model with categorical question type feature</figcaption>
</figure>
</div>



 ]]></description>
  <category>news</category>
  <guid>https://CDU-data-science-team.github.io/PatientExperience-QDC/posts/update-23-03-13/index.html</guid>
  <pubDate>Mon, 13 Mar 2023 00:00:00 GMT</pubDate>
  <media:content url="https://CDU-data-science-team.github.io/PatientExperience-QDC/posts/update-23-03-13/model_architecture.png" medium="image" type="image/png" height="107" width="144"/>
</item>
</channel>
</rss>
